{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch neural net for music genre classification\n",
    "\n",
    "This notebook trains a Pytorch feed forward neural net to do multiclass classification of music genre based on training data containing the following:\n",
    "\n",
    "1. Intensity of particular instruments representing one of 8 music genres (represented as a list of np.array float32)\n",
    "2. A integer label [0-7] representing the following music genres ['DRUM & BASS':0, 'R&B':1, 'BLUES':2, 'VOCAL JAZZ':3, 'NATURE SOUNDS':4, 'BAROQUE':5, 'DISNEY':6, 'HARD ROCK':7]\n",
    "\n",
    "Currently the entire training & inference is run locally on the machine running the notebook therefore GPU is required on the Notebook host however next iteration of this will leverage Sagemaker for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn datasets and train_test_split\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import helper libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the datasets\n",
    "bucketname = 'BUCKET_NAME' # replace with your S3 bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucketname).download_file('pytorch-multiclass/data/DL1_Train.pkl', '../data/DL1_Train.pkl')\n",
    "s3.Bucket(bucketname).download_file('pytorch-multiclass/data/DL1_Test.pkl', '../data/DL1_Test.pkl')\n",
    "\n",
    "final_train = pickle.load( open( \"../data/DL1_Train.pkl\", \"rb\" ), encoding='latin1')\n",
    "final_test = pickle.load( open( \"../data/DL1_Test.pkl\", \"rb\" ), encoding='latin1')\n",
    "\n",
    "td = {'DRUM & BASS':0, 'R&B':1, 'BLUES':2, 'VOCAL JAZZ':3, 'NATURE SOUNDS':4, 'BAROQUE':5, 'DISNEY':6, 'HARD ROCK':7}\n",
    "\n",
    "X = np.array([final_train[key]['PACH'] for key in final_train.keys() if len(final_train[key]['text_genre']) == 1])\n",
    "y = np.array([td[final_train[key]['text_genre'][0]] for key in final_train.keys() if len(final_train[key]['text_genre']) == 1])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 8675309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_dataset = data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)) \n",
    "final_train_loader = data.DataLoader(final_train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "final_val_dataset = data.TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val)) \n",
    "final_val_loader = data.DataLoader(final_val_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            # Required for BERT Fine-tuning (to be covered later)\n",
    "            X = [x.to(device) for x in X]\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Flatten(), \n",
    "                     nn.Dropout(.2), \n",
    "                     nn.Linear(4096, 1024), \n",
    "                     nn.ReLU(),\n",
    "                     nn.BatchNorm1d(1024), \n",
    "                     nn.Dropout(.5), \n",
    "                     nn.Linear(1024, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_iter, test_iter, num_epochs = 20, device=d2l.try_gpu(), lrate=0.005):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    test_losses = []\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[0, num_epochs],\n",
    "                            legend=['val acc'])\n",
    "    timer = d2l.Timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(2)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(final_train_loader):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            metric.add(l.sum(),  X.shape[0])\n",
    "            timer.stop()\n",
    "            train_loss = metric[0]/metric[1]\n",
    "        test_acc = evaluate_accuracy_gpu(net, final_val_loader)\n",
    "        animator.add(epoch+1, (test_acc))\n",
    "    print('validation acc %.3f' % (test_acc))\n",
    "    print('%.1f examples/sec on %s' % (metric[1]*num_epochs/timer.sum(), device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8675309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(net, final_train_loader, final_val_loader, num_epochs = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = np.array(final_test[\"test_data\"])\n",
    "final_X = torch.from_numpy(final_X).to(d2l.try_gpu())\n",
    "\n",
    "preds = torch.argmax(net(final_X), axis=1).type(torch.long)\n",
    "\n",
    "genre_list = [\n",
    "    \"DRUM & BASS\",\n",
    "    \"R&B\",\n",
    "    \"BLUES\",\n",
    "    \"VOCAL JAZZ\",\n",
    "    \"NATURE SOUNDS\",\n",
    "    \"BAROQUE\",\n",
    "    \"DISNEY\",\n",
    "    \"HARD ROCK\",\n",
    "]\n",
    "predictions = [genre_list[p] for p in preds.tolist()]\n",
    "df_out = pd.DataFrame()\n",
    "df_out[\"ID\"] = final_test[\"test_labels\"]\n",
    "df_out[\"genre\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(\"./NN_music_genre.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
